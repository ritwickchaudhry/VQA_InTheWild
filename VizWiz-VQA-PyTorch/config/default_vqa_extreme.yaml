logs:
    dir_logs: logs/vqa/transform_test # CHANGE BEFORE RUN
annotations:
    type: "vqa"
    dir: /home/ubuntu/data_vqa/Annotations
    questions_dir: /home/ubuntu/data_vqa/Annotations/questions
    top_ans: 3000
    max_length: 40
    min_count_word: 0
    path_vocabs: /home/ubuntu/prepro_data/vqa/vocabs.json
    ans_count: 10
images:
    dir: /home/ubuntu/data_vqa/Images
    dir_prefix: COCO_split2014_000000
    arch: ResNet152
    mode: attention
    img_size: 448
    preprocess_batch_size: 32
    preprocess_data_workers: 8
    path_features: /home/ubuntu/prepro_data/vqa/image_features
    preprocessed: False
    trainable: True
    save_transformed_sample: 100
    save_transformed_path: /home/ubuntu/data_vqa/transform/mid_perturb
    augmentation:
        extreme_perturb: false
        extreme_ans: "unanswerable"
        extreme_p: 0.1
        e_blur_size: 55
        e_blur_sigma: 9
        e_crop_scale: [0.5, 0.75]
        e_crop_ratio: [0.5, 1.5]
        e_erasing_probability: 0.8
        e_erasing_scale: [0.1, 0.3]
        save_transformed_path: ""
        do_crop: true
        do_blur: true
        do_erasing: true
        blur_size: 31
        blur_sigma: 5
        crop_scale: [0.6, 0.8]
        crop_ratio: [0.5, 1.5]
        erasing_probability: 1
        erasing_scale: [0.05, 0.2]

model:
# Could be added new architectures and hyper-parameters like activations etc
    pretrained:
        use_pretrained: false
        use_full_weights: false
        pretrained_model_path: ""
        transfer_image_feature_extractor: false
        freeze_image_feature_extractor: false
        transfer_attention_network: false
        freeze_attention_network: false
    seq2vec:
        dropout: 0.25
        emb_size: 300
    pooling:
        dim_v: 2048
        dim_q: 512 # 1024
        dim_h: 512 # 1024
        dropout_v: 0.5
        dropout_q: 0.5
    classifier:
        dropout: 0.5
    attention:
        glimpses: 2
        mid_features: 512
        dropout: 0.5
training:
    train_split: train
    lr: 0.0001
    batch_size: 32
    epochs: 2
    data_workers: 0
    patience: 5
    snap_freq: 2500
    val_freq: 5000

prediction:
    model_path: ./logs/vqa/mid_perturbations/best_accuracy_log.pth
    split: test
    submission_file: ./predictions/default_pred.json

